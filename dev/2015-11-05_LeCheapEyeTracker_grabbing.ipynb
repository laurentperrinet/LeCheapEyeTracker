{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple tests for grabbing frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV has a nice wrapper around webcams. Let's test it there to get the simplest code that we would need in our library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "# define plots to be inserted interactively\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Source:\n",
    "    def __init__(self, w=640, h=480):\n",
    "        self.h, self.w = h, w\n",
    "        import cv2\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.w)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.h)\n",
    "      \n",
    "    def grab(self):\n",
    "        # grab a frame\n",
    "        returned, cam_data = self.cap.read()\n",
    "        data = cam_data.reshape((self.h, self.w, 3))\n",
    "        return data\n",
    "    \n",
    "    def close(self):\n",
    "        self.cap.release()\n",
    "        del self.cap\n",
    "\n",
    "start = time.time()\n",
    "cam = Source()\n",
    "cam.close()\n",
    "print('Time to start and stop the camera = ',  time.time() - start , '(s)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is implemented in the ``LeCheapEyeTracker``class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from openRetina import PhotoReceptor\n",
    "\n",
    "cam = PhotoReceptor()\n",
    "cam.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for DOWNSCALE in [1, 2, 4, 8, 16]:\n",
    "    start = time.time()\n",
    "    cam = PhotoReceptor(DOWNSCALE=DOWNSCALE)\n",
    "    cam.close()\n",
    "    print('DOWNSCALE = ', DOWNSCALE, 'startup= ',  time.time() - start , '(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "cam = PhotoReceptor(DOWNSCALE=2)\n",
    "img = cam.grab()\n",
    "img = cam.grab()\n",
    "cam.close()\n",
    "print('Time to start, grab 2 frames and stop = ',  time.time() - start , '(s)')\n",
    "print(img.shape, img.min(), img.max())\n",
    "_ = plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for DOWNSCALE in [1, 2, 4, 8, 16]:\n",
    "    cam = PhotoReceptor(DOWNSCALE=DOWNSCALE)\n",
    "    start = time.time()\n",
    "    img = cam.grab()\n",
    "    img = cam.grab()\n",
    "    cam.close()\n",
    "    print('DOWNSCALE = ', DOWNSCALE, 'grab time= ',  time.time() - start , '(s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how fast do we grab frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "ctime = np.zeros(N)\n",
    "start = time.time()\n",
    "cam = PhotoReceptor()\n",
    "for i in range(N):\n",
    "    img = cam.grab()\n",
    "    ctime[i] = time.time() - start\n",
    "cam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(ctime[1:], np.diff(ctime)*1000, '+')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('inter-frame interval(ms)')\n",
    "_ = plt.axis('tight')\n",
    "print ('FPS : ',  N/(ctime[-1]-ctime[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## closing the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cam = PhotoReceptor()\n",
    "cam.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## threaded mode\n",
    "\n",
    "Following the documentation @ http://docs.opencv.org/modules/highgui/doc/reading_and_writing_images_and_video.html?highlight=imread it is easy to run parallel captures :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "from collections import deque\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "class StatValue:\n",
    "    def __init__(self, smooth_coef = 0.5):\n",
    "        self.value = None\n",
    "        self.smooth_coef = smooth_coef\n",
    "    def update(self, v):\n",
    "        if self.value is None:\n",
    "            self.value = v\n",
    "        else:\n",
    "            c = self.smooth_coef\n",
    "            self.value = c * self.value + (1.0-c) * v\n",
    "\n",
    "def clock():\n",
    "    return cv2.getTickCount() / cv2.getTickFrequency()\n",
    "\n",
    "def draw_str(dst, target, s):\n",
    "    x, y = target\n",
    "    cv2.putText(dst, s, (x+1, y+1), cv2.FONT_HERSHEY_PLAIN, 1.0, (0, 0, 0), thickness = 2, lineType=cv2.LINE_AA)\n",
    "    cv2.putText(dst, s, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.0, (255, 255, 255), lineType=cv2.LINE_AA)\n",
    "\n",
    "\n",
    "class ThreadSource:\n",
    "    def __init__(self, w=640, h=480, threads=True):\n",
    "        self.h, self.w = h, w\n",
    "        import cv2\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.w)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.h)\n",
    "\n",
    "        if threads:\n",
    "            self.threadn = cv2.getNumberOfCPUs()\n",
    "        else:\n",
    "            self.threadn = 1\n",
    "        self.pool = ThreadPool(processes = self.threadn)\n",
    "        self.pending = deque()\n",
    "\n",
    "        self.latency = StatValue()\n",
    "        self.frame_interval = StatValue()\n",
    "        self.last_frame_time = clock()        \n",
    "        self.display = False\n",
    "        self.ctime = []\n",
    "        self.N = 0\n",
    "\n",
    "    def process_frame(self, frame, t0):\n",
    "        # some intensive computation...\n",
    "        frame = cv2.medianBlur(frame, 19)\n",
    "        time.sleep(.1)\n",
    "        frame = cv2.medianBlur(frame, 19)\n",
    "        return frame, t0\n",
    "\n",
    "    def run(self, T=10):\n",
    "        start = clock()\n",
    "        while clock()-start <10.:\n",
    "            while len(self.pending) > 0 and self.pending[0].ready():\n",
    "                res, t0 = self.pending.popleft().get()\n",
    "                self.latency.update(clock() - t0)\n",
    "                if self.display:\n",
    "                    draw_str(res, (20, 40), \"latency        :  %.1f ms\" % (self.latency.value*1000))\n",
    "                    draw_str(res, (20, 60), \"frame interval :  %.1f ms\" % (self.frame_interval.value*1000))\n",
    "                    cv2.imshow('Webcam video', res)\n",
    "                self.ctime.append(time.time() - start)\n",
    "                self.N += 1\n",
    "            if len(self.pending) < self.threadn:\n",
    "                ret, frame = self.cap.read()\n",
    "                t = clock()\n",
    "                self.frame_interval.update(t - self.last_frame_time)\n",
    "                self.last_frame_time = t\n",
    "                task = self.pool.apply_async(self.process_frame, (frame.copy(), t))\n",
    "                self.pending.append(task)\n",
    "            ch = 0xFF & cv2.waitKey(1)\n",
    "            if ch == 27:\n",
    "                self.close()\n",
    "    \n",
    "    def close(self):\n",
    "        self.cap.release()\n",
    "        if self.display: cv2.destroyAllWindows()\n",
    "\n",
    "start = time.time()\n",
    "cam = ThreadSource()\n",
    "ctime = cam.run()\n",
    "cam.close()\n",
    "start_nothreads = time.time()\n",
    "cam_nothreads = ThreadSource(threads=False)\n",
    "ctime = cam_nothreads.run()\n",
    "cam_nothreads.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.array(cam.ctime)[1:]-cam.ctime[0], np.diff(np.array(cam.ctime))*1000, 'b+')\n",
    "plt.plot(np.array(cam_nothreads.ctime)[1:]-cam_nothreads.ctime[0], np.diff(np.array(cam_nothreads.ctime))*1000, 'rx')\n",
    "plt.xlabel('time (s)')\n",
    "plt.ylabel('inter-frame interval(ms)')\n",
    "_ = plt.axis('tight')\n",
    "print ('FPS threaded: ',  cam.N/(cam.ctime[-1]-cam.ctime[0]))\n",
    "print ('FPS one thread: ',  cam_nothreads.N/(cam_nothreads.ctime[-1]-cam_nothreads.ctime[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In practice, we will see nice improvments when the image processing pipeline is more consequent. This threaded mode is enabled by default.\n",
    "\n",
    "##  creating a video for debugging\n",
    "\n",
    "It may be sometimes useful to just read out some frames for debugging: move your eyes, not the head = we grab 42 frames. why 42? I recommend to not move the head (hold them in your hands) and to look at the led of your webcam. when it's lit, move your eyes evenly on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_0.png\n",
      "frame_1.png\n",
      "frame_2.png\n",
      "frame_3.png\n",
      "frame_4.png\n",
      "frame_5.png\n",
      "frame_6.png\n",
      "frame_7.png\n",
      "frame_8.png\n",
      "frame_9.png\n",
      "frame_10.png\n",
      "frame_11.png\n",
      "frame_12.png\n",
      "frame_13.png\n",
      "frame_14.png\n",
      "frame_15.png\n",
      "frame_16.png\n",
      "frame_17.png\n",
      "frame_18.png\n",
      "frame_19.png\n",
      "frame_20.png\n",
      "frame_21.png\n",
      "frame_22.png\n",
      "frame_23.png\n",
      "frame_24.png\n",
      "frame_25.png\n",
      "frame_26.png\n",
      "frame_27.png\n",
      "frame_28.png\n",
      "frame_29.png\n",
      "frame_30.png\n",
      "frame_31.png\n",
      "frame_32.png\n",
      "frame_33.png\n",
      "frame_34.png\n",
      "frame_35.png\n",
      "frame_36.png\n",
      "frame_37.png\n",
      "frame_38.png\n",
      "frame_39.png\n",
      "frame_40.png\n",
      "frame_41.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "N_frame = 42 # how much you want?\n",
    "folder = '/tmp/debug' # where we do save the frames\n",
    "try: \n",
    "    os.mkdir(folder)\n",
    "except: pass\n",
    "\n",
    "from openRetina import PhotoReceptor\n",
    "cam = PhotoReceptor()\n",
    "\n",
    "time.sleep(1.5)\n",
    "\n",
    "start = time.time()\n",
    "for i in range(N_frame):\n",
    "    frame = cam.grab()\n",
    "    t = time.time() - start   \n",
    "    # https://docs.python.org/3.3/library/string.html#format-examples\n",
    "    timestr = '{t:03.5f}'.format(t=t).replace('.', '_')\n",
    "    fname = 'frame_{i}.png'.format(i=i)\n",
    "    print(fname)\n",
    "    cv2.imwrite(os.path.join(folder, fname), frame)\n",
    "    time.sleep(0.3)\n",
    "\n",
    "cam.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using the class in LecheapEyeTracker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cam = PhotoReceptor()\n",
    "cam.run(T=8)\n",
    "cam.close()\n",
    "if len(cam.ctime) > 0:\n",
    "    plt.plot(np.diff(np.array(cam.ctime))*1000, '+')\n",
    "    _ = plt.axis('tight')\n",
    "    print ('FPS : ',  len(cam.ctime)/(cam.ctime[-1]-cam.ctime[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
